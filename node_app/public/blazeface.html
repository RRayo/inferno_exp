<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Face Detection</title>
</head>
<body>
    <h1>Face Detection</h1>
    <video id="video" autoplay style="display: none"></video>
    <canvas id="canvas" width="600px" height="400px"></canvas>
</body>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
<script>
    let video = document.getElementById("video");
    let model;
    // declare a canvas variable and get its context
    let canvas = document.getElementById("canvas");
    let ctx = canvas.getContext("2d");
    
    const setupCamera = () => {
        navigator.mediaDevices
        .getUserMedia({
            video: { width: 600, height: 400 },
            audio: false,
        })
        .then((stream) => {
            video.srcObject = stream;
        });
    };
    
    const detectFaces = async () => {
        const prediction = await model.estimateFaces(video, false);
        
        // draw the video first
        ctx.drawImage(video, 0, 0, 600, 400);
        
        prediction.forEach((pred) => {
            
            // draw the rectangle enclosing the face
            ctx.beginPath();
            ctx.lineWidth = "4";
            ctx.strokeStyle = "blue";
            // the last two arguments are width and height
            // since blazeface returned only the coordinates, 
            // we can find the width and height by subtracting them.
            ctx.rect(
            pred.topLeft[0],
            pred.topLeft[1],
            pred.bottomRight[0] - pred.topLeft[0],
            pred.bottomRight[1] - pred.topLeft[1]
            );
            ctx.stroke();
            
            // drawing small rectangles for the face landmarks
            ctx.fillStyle = "red";
            pred.landmarks.forEach((landmark) => {
                ctx.fillRect(landmark[0], landmark[1], 5, 5);
            });
            
            // draw the probability / confidence above the rectangle
            // BlazeFace returns a probability in pred.probability which may be
            // a single number or an array (for some model variants). Normalize
            // to a percentage and render with a semi-transparent background
            let prob = 0;
            if (pred.probability !== undefined) {
                if (Array.isArray(pred.probability)) {
                    // choose the highest probability if an array is returned
                    prob = Math.max(...pred.probability);
                } else {
                    prob = pred.probability;
                }
            }

            // format as percentage
            const percent = Math.round((prob || 0) * 100);
            const label = percent + "%";

            // measure text and draw a filled rounded rectangle behind it for readability
            ctx.font = "16px sans-serif";
            ctx.textBaseline = "bottom";
            const textWidth = ctx.measureText(label).width;
            const padding = 6;

            const x = pred.topLeft[0];
            const y = pred.topLeft[1] - 8; // slightly above the box

            // background
            ctx.fillStyle = "rgba(0, 0, 255, 0.6)"; // semi-transparent blue
            // draw a filled rect behind the text
            ctx.fillRect(x - 2, y - 16, textWidth + padding, 18);

            // text
            ctx.fillStyle = "white";
            ctx.fillText(label, x + padding / 2, y);
            
        });
    };
    
    setupCamera();
    video.addEventListener("loadeddata", async () => {
        model = await blazeface.load();
        // call detect faces every 100 milliseconds or 10 times every second
        setInterval(detectFaces, 100);
    });
</script>
</html>