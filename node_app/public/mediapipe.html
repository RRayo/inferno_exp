<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Face Detection</title>
  <script type="module">
    import { FaceDetector, FilesetResolver } from "./tasks-vision@0.10.0.js";
    
    let faceDetector;
    let runningMode = "IMAGE";
    const video = document.getElementById("webcam");
    const liveView = document.getElementById("liveView");
    const children = [];
    
    let canSave = true;
    let consecutiveFramesCounter = 0;
    const requiredConsecutiveFrames = 5; 
    
    async function initializeFaceDetector() {
      const vision = await FilesetResolver.forVisionTasks(
      "./task_vision"
      );
      faceDetector = await FaceDetector.createFromOptions(vision, {
        baseOptions: { modelAssetPath: "blaze_face_short_range.tflite", delegate: "GPU" },
        runningMode
      });
      startWebcam();
    }
    
    function hasGetUserMedia() {
      return !!navigator.mediaDevices?.getUserMedia;
    }
    
    async function startWebcam() {
      if (!faceDetector || !hasGetUserMedia()) return;
      
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        video.addEventListener("loadeddata", predictWebcam);
      } catch (err) {
        console.error("No se pudo acceder a la webcam:", err);
      }
    }
    
    let lastVideoTime = -1;
    async function predictWebcam() {
      // Ajustar el modo de ejecución la primera vez
      if (runningMode === "IMAGE") {
        runningMode = "VIDEO";
        await faceDetector.setOptions({ runningMode });
      }
      
      const startTimeMs = performance.now();
      if (video.currentTime !== lastVideoTime) {
        lastVideoTime = video.currentTime;
        const detections = faceDetector.detectForVideo(video, startTimeMs)?.detections;
        if (detections) {
          displayDetections(detections);
        }
      }
      requestAnimationFrame(predictWebcam);
    }
    
    function displayDetections(detections) {
      // Limpiar detecciones anteriores
      for (let child of children) liveView.removeChild(child);
      children.length = 0;
      
      // --- INICIO DE LA LÓGICA DE CÁLCULO MODIFICADA ---
      // Obtener las dimensiones reales del video y del elemento en pantalla
      const videoRatio = video.videoWidth / video.videoHeight;
      const viewRatio = video.clientWidth / video.clientHeight;
      
      let scale = 1;
      let offsetX = 0;
      let offsetY = 0;
      
      // 'object-fit: cover' escala el video para llenar el contenedor.
      // Necesitamos replicar esa lógica para que las coordenadas coincidan.
      if (videoRatio > viewRatio) {
        // El video es más ancho que la vista, se ajusta a la altura y se recorta horizontalmente.
        scale = video.clientHeight / video.videoHeight;
        offsetX = (video.clientWidth - video.videoWidth * scale) / 2;
      } else {
        // El video es más alto que la vista, se ajusta al ancho y se recorta verticalmente.
        scale = video.clientWidth / video.videoWidth;
        offsetY = (video.clientHeight - video.videoHeight * scale) / 2;
      }
      // --- FIN DE LA LÓGICA DE CÁLCULO MODIFICADA ---
      
      
      for (let det of detections) {
        const confidence = Math.round(det.categories[0].score * 100);

        // Verificar si la cara está de frente
        const facingForward = isFacingForward(det.keypoints);
        // Si se cumplen las condiciones actuales, incrementamos el contador.
        if (confidence > 0.90 && facingForward) {
          consecutiveFramesCounter++;
        } else {
          // Si alguna de las condiciones falla, reiniciamos el contador a cero.
          consecutiveFramesCounter = 0;
        }
        // Guardar la imagen si la confianza es alta, está viendo al frente y no se ha guardado recientemente
        if (canSave && consecutiveFramesCounter >= requiredConsecutiveFrames) {
          console.log("Guardando imagen con confianza del", confidence, "%");
          canSave = false; // Evitar múltiples guardados
          saveFrame();
          consecutiveFramesCounter = 0;
        }

        // Calcular las dimensiones y posiciones escaladas
        const scaledWidth = det.boundingBox.width * scale;
        const scaledHeight = det.boundingBox.height * scale;
        const scaledOriginX = det.boundingBox.originX * scale;
        const scaledOriginY = det.boundingBox.originY * scale;
        
        // Bounding box
        const box = document.createElement("div");
        box.className = "highlighter";
        
        // La lógica del `left` se ajusta para el espejo (transform: rotateY(180deg))
        // y para el nuevo escalado y desplazamiento.
        box.style.cssText = `
          left:${video.clientWidth - scaledOriginX - scaledWidth - offsetX}px;
          top:${scaledOriginY + offsetY}px;
          width:${scaledWidth}px;
          height:${scaledHeight}px;
        `;
        liveView.appendChild(box);
        children.push(box);
        
        // Confianza
        const p = document.createElement("p");
        p.innerText = "Confidence: " + confidence + "%";
        p.style.cssText = `
          left:${video.clientWidth - scaledOriginX - scaledWidth - offsetX}px;
          top:${scaledOriginY + offsetY - 30}px;
          width:${scaledWidth}px;
        `;
        liveView.appendChild(p);
        children.push(p);
        
        // Keypoints
        for (let k of det.keypoints) {
          const kp = document.createElement("span");
          kp.className = "key-point";
          
          // Se aplica la misma lógica de escalado, desplazamiento y espejo a los keypoints
          const keypointX = video.clientWidth - (k.x * video.videoWidth * scale) - offsetX;
          const keypointY = (k.y * video.videoHeight * scale) + offsetY;
          
          kp.style.left = `${keypointX - 3}px`;
          kp.style.top = `${keypointY - 3}px`;
          liveView.appendChild(kp);
          children.push(kp);
        }
      }
    }
    
    function isFacingForward(keypoints) {
      // MediaPipe Face Detector proporciona 6 keypoints en este orden:
      // 0: Ojo izquierdo, 1: Ojo derecho, 2: Punta de la nariz, 3: Boca, 4: Oreja izquierda, 5: Oreja derecha
      const leftEye = keypoints[0];
      const rightEye = keypoints[1];
      const noseTip = keypoints[2];
      
      // Calculamos la distancia horizontal de la nariz a cada ojo.
      // Usamos Math.abs para asegurarnos de que la distancia sea siempre positiva.
      const distNoseToLeftEye = Math.abs(noseTip.x - leftEye.x);
      const distNoseToRightEye = Math.abs(noseTip.x - rightEye.x);
      
      // Para evitar dividir por cero si alguna distancia es 0
      if (distNoseToLeftEye === 0 || distNoseToRightEye === 0) {
        return false;
      }
      
      // Calculamos el ratio dividiendo la distancia más pequeña por la más grande.
      // Un rostro de frente tendrá un ratio cercano a 1.
      const ratio = Math.min(distNoseToLeftEye, distNoseToRightEye) / Math.max(distNoseToLeftEye, distNoseToRightEye);
      
      // Definimos nuestro umbral. Si el ratio es mayor a 0.7, consideramos que está de frente.
      // Puedes ajustar este valor para hacerlo más o menos estricto.
      const frontalThreshold = 0.7; 
      
      return ratio > frontalThreshold;
    }
    
    
    
    /**
    * Versión Simplificada de saveFrame
    * Captura y descarga el fotograma actual del video sin añadir dibujos.
    */
    function saveFrame() {
      const canvas = document.getElementById("snapshotCanvas");
      const ctx = canvas.getContext("2d");
      
      // 1. Ajustar el tamaño del canvas al del video
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      
      // 2. Voltear el canvas horizontalmente para cancelar el efecto espejo
      ctx.translate(canvas.width, 0);
      ctx.scale(-1, 1);
      
      // 3. Dibujar el fotograma actual del video en el canvas
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      
      // (Se han eliminado todos los pasos de dibujo de la caja, texto y puntos)
      
      // 4. Crear un enlace de descarga y simular un clic
      const link = document.createElement('a');
      const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
      link.download = `captura-${timestamp}.png`;
      link.href = canvas.toDataURL("image/png");
      link.click();
      
      console.log("Frame guardado con éxito.");
    }
    
    initializeFaceDetector();
  </script>
  <style>
    /* --- INICIO DE ESTILOS MODIFICADOS --- */
    html, body {
      margin: 0;
      padding: 0;
      height: 100%;
      width: 100%;
      overflow: hidden; /* Evita barras de scroll */
      font-family: roboto, sans-serif;
      color: #3d3d3d;
    }
    
    h1 {
      position: absolute;
      top: 20px;
      left: 20px;
      color: white;
      background-color: rgba(0, 0, 0, 0.5);
      padding: 10px;
      border-radius: 5px;
      z-index: 10;
    }
    
    .videoView {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      display: flex;
      justify-content: center;
      align-items: center;
    }
    
    video {
      /* Esto asegura que el video siempre cubra toda la altura de la pantalla,
      manteniendo su aspect ratio y centrando/recortando el exceso horizontal */
      width: 100%;
      height: 100%;
      object-fit: cover;
      transform: rotateY(180deg);
      -webkit-transform: rotateY(180deg); /* Safari & iOS */
    }
    
    .highlighter {
      position: absolute;
      /* Color cambiado a un blanco casi transparente */
      background: rgba(255, 255, 255, 0.1);
      border: 1px dashed #fff;
      z-index: 1;
    }
    /* --- FIN DE ESTILOS MODIFICADOS --- */
    
    .key-point {
      position: absolute;
      width: 3px;
      height: 3px;
      background: red;
      border-radius: 50%;
      z-index: 2;
    }
    
    p {
      position: absolute;
      padding: 5px;
      background: #007f8b;
      color: #fff;
      font-size: 12px;
      margin: 0;
      z-index: 2;
    }
  </style>
</head>
<body>
  <h1>Face Detection Demo</h1>
  <div id="liveView" class="videoView">
    <video id="webcam" autoplay playsinline></video>
  </div>
  <canvas id="snapshotCanvas" style="display: none;"></canvas>
</body>
</html>