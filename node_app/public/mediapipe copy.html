<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Face Detection</title>
  <script type="module">
    import { FaceDetector, FilesetResolver } from "./tasks-vision@0.10.0.js";
    
    let faceDetector;
    let runningMode = "IMAGE";
    const video = document.getElementById("webcam");
    const liveView = document.getElementById("liveView");
    const children = [];
    
    const min_score = 0.90; // Umbral de confianza mínimo para considerar una detección válida
    const requiredConsecutiveFrames = 60; // Número de frames consecutivos necesarios para guardar
    let canSave = true;
    let consecutiveFramesCounter = 0;
    let isPhotoTaken = false;
    let mensajeExitoMostrado = false;
    
    async function initializeFaceDetector() {
      const vision = await FilesetResolver.forVisionTasks(
      "./task_vision"
      );
      faceDetector = await FaceDetector.createFromOptions(vision, {
        baseOptions: { modelAssetPath: "blaze_face_short_range.tflite", delegate: "GPU" },
        runningMode
      });
      startWebcam();
    }
    
    function hasGetUserMedia() {
      return !!navigator.mediaDevices?.getUserMedia;
    }
    
    async function startWebcam() {
      if (!faceDetector || !hasGetUserMedia()) return;
      
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        video.addEventListener("loadeddata", predictWebcam);
      } catch (err) {
        console.error("No se pudo acceder a la webcam:", err);
      }
    }
    
    let lastVideoTime = -1;
    async function predictWebcam() {
      // Ajustar el modo de ejecución la primera vez
      if (runningMode === "IMAGE") {
        runningMode = "VIDEO";
        await faceDetector.setOptions({ runningMode });
      }
      
      const startTimeMs = performance.now();
      if (video.currentTime !== lastVideoTime) {
        lastVideoTime = video.currentTime;
        if(!mensajeExitoMostrado){
          const detections = faceDetector.detectForVideo(video, startTimeMs)?.detections;
          if (detections) {
            displayDetections(detections);
          }
        }
      }
      requestAnimationFrame(predictWebcam);
    }
    
    function displayDetections(detections) {
      // Limpiar detecciones anteriores
      for (let child of children) liveView.removeChild(child);
      children.length = 0;
      
      // Si la foto ya fue tomada, muestra el mensaje de éxito y detén todo.
      if (isPhotoTaken) {
        const p = document.createElement("p");
        p.innerText = "¡Captura completada!";
        p.style.backgroundColor = "#009933"; // Fondo verde de éxito
        p.style.color = "white";
        p.style.position = 'absolute';
        p.style.top = '20p';
        p.style.left = '50%';
        p.style.transform = 'translateX(-50%)'; // Centrar horizontal
        p.style.padding = '20px';
        p.style.borderRadius = '10px';
        p.style.fontSize = '24px';
        liveView.appendChild(p);
        children.push(p);
        if (!mensajeExitoMostrado) {
          console.log("Captura completada. Puedes cerrar esta ventana.");
          mensajeExitoMostrado = true;
        }
        return;
      }
      
      const videoRatio = video.videoWidth / video.videoHeight;
      const viewRatio = video.clientWidth / video.clientHeight;
      let scale = 1, offsetX = 0, offsetY = 0;
      if (videoRatio > viewRatio) {
        scale = video.clientHeight / video.videoHeight;
        offsetX = (video.clientWidth - video.videoWidth * scale) / 2;
      } else {
        scale = video.clientWidth / video.videoWidth;
        offsetY = (video.clientHeight - video.videoHeight * scale) / 2;
      }
      
      // --- Bucle principal de detección (solo se ejecuta si isPhotoTaken es false) ---
      for (let det of detections) {
        const score = det.categories[0].score;
        const isFrontal = isFacingForward(det.keypoints);
        
        if (score > min_score && isFrontal) {
          consecutiveFramesCounter++;
        } else {
          consecutiveFramesCounter = 0;
        }
        
        // Condición de guardado
        if (consecutiveFramesCounter >= requiredConsecutiveFrames && canSave) {
          console.log("Guardando imagen con confianza del", Math.round(score * 100), "%");
          canSave = false;
          saveFrame();
          isPhotoTaken = true; 
          // Salimos de la función. En el próximo frame, se ejecutará la lógica de "estado final".
          return; 
        }
        const scaledWidth = det.boundingBox.width * scale;
        const scaledHeight = det.boundingBox.height * scale;
        const scaledOriginX = det.boundingBox.originX * scale;
        const scaledOriginY = det.boundingBox.originY * scale;
        
        const box = document.createElement("div");
        box.className = "highlighter";
        box.style.cssText = `left:${video.clientWidth - scaledOriginX - scaledWidth - offsetX}px; top:${scaledOriginY + offsetY}px; width:${scaledWidth}px; height:${scaledHeight}px;`;
        box.style.borderColor = (consecutiveFramesCounter > 0) ? "#00FF00" : "#FFFFFF";
        liveView.appendChild(box);
        children.push(box);
        
        const p = document.createElement("p");
        let statusText = "";
        if (consecutiveFramesCounter > 0 && consecutiveFramesCounter < requiredConsecutiveFrames) {
          const progress = Math.round((consecutiveFramesCounter / requiredConsecutiveFrames) * 100);
          statusText = `Mantén la posición... ${progress}%`;
          p.style.backgroundColor = "#E67E22";
        } else if (score > 0.90 && isFrontal) {
          statusText = "Posición correcta. ¡Espera!";
          p.style.backgroundColor = "#009933";
        } else {
          statusText = "Buscando rostro frontal...";
          p.style.backgroundColor = "#CC3300";
        }
        p.innerText = statusText;
        p.style.left = `${video.clientWidth - scaledOriginX - scaledWidth - offsetX}px`;
        p.style.top = `${scaledOriginY + offsetY - 35}px`;
        p.style.width = `${scaledWidth}px`;
        p.style.textAlign = 'center';
        liveView.appendChild(p);
        children.push(p);
        
        for (let k of det.keypoints) {
          const kp = document.createElement("span");
          kp.className = "key-point";
          const keypointX = video.clientWidth - (k.x * video.videoWidth * scale) - offsetX;
          const keypointY = (k.y * video.videoHeight * scale) + offsetY;
          kp.style.left = `${keypointX - 3}px`;
          kp.style.top = `${keypointY - 3}px`;
          liveView.appendChild(kp);
          children.push(kp);
        }
      }
    }
    
    function isFacingForward(keypoints) {
      // MediaPipe Face Detector proporciona 6 keypoints en este orden:
      // 0: Ojo izquierdo, 1: Ojo derecho, 2: Punta de la nariz, 3: Boca, 4: Oreja izquierda, 5: Oreja derecha
      const leftEye = keypoints[0];
      const rightEye = keypoints[1];
      const noseTip = keypoints[2];
      
      // Calculamos la distancia horizontal de la nariz a cada ojo.
      // Usamos Math.abs para asegurarnos de que la distancia sea siempre positiva.
      const distNoseToLeftEye = Math.abs(noseTip.x - leftEye.x);
      const distNoseToRightEye = Math.abs(noseTip.x - rightEye.x);
      
      // Para evitar dividir por cero si alguna distancia es 0
      if (distNoseToLeftEye === 0 || distNoseToRightEye === 0) {
        return false;
      }
      
      // Calculamos el ratio dividiendo la distancia más pequeña por la más grande.
      // Un rostro de frente tendrá un ratio cercano a 1.
      const ratio = Math.min(distNoseToLeftEye, distNoseToRightEye) / Math.max(distNoseToLeftEye, distNoseToRightEye);
      
      // Definimos nuestro umbral. Si el ratio es mayor a 0.7, consideramos que está de frente.
      // Puedes ajustar este valor para hacerlo más o menos estricto.
      const frontalThreshold = 0.7; 
      
      return ratio > frontalThreshold;
    }
    
    
    
    /**
    * Versión Simplificada de saveFrame
    * Captura y descarga el fotograma actual del video sin añadir dibujos.
    */
    function saveFrame() {
      const canvas = document.getElementById("snapshotCanvas");
      const ctx = canvas.getContext("2d");
      
      // 1. Ajustar el tamaño del canvas al del video
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      
      // 2. Voltear el canvas horizontalmente para cancelar el efecto espejo
      ctx.translate(canvas.width, 0);
      ctx.scale(-1, 1);
      
      // 3. Dibujar el fotograma actual del video en el canvas
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      
      // (Se han eliminado todos los pasos de dibujo de la caja, texto y puntos)
      
      // 4. Crear un enlace de descarga y simular un clic
      const link = document.createElement('a');
      const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
      link.download = `captura-${timestamp}.png`;
      link.href = canvas.toDataURL("image/png");
      link.click();
      
      console.log("Frame guardado con éxito.");
    }
    
    initializeFaceDetector();
  </script>
  <style>
    /* --- INICIO DE ESTILOS MODIFICADOS --- */
    html, body {
      margin: 0;
      padding: 0;
      height: 100%;
      width: 100%;
      overflow: hidden; /* Evita barras de scroll */
      font-family: roboto, sans-serif;
      color: #3d3d3d;
    }
    
    h1 {
      position: absolute;
      top: 20px;
      left: 20px;
      color: white;
      background-color: rgba(0, 0, 0, 0.5);
      padding: 10px;
      border-radius: 5px;
      z-index: 10;
    }
    
    .videoView {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      display: flex;
      justify-content: center;
      align-items: center;
    }
    
    video {
      /* Esto asegura que el video siempre cubra toda la altura de la pantalla,
      manteniendo su aspect ratio y centrando/recortando el exceso horizontal */
      width: 100%;
      height: 100%;
      object-fit: cover;
      transform: rotateY(180deg);
      -webkit-transform: rotateY(180deg); /* Safari & iOS */
    }
    
    .highlighter {
      position: absolute;
      /* Color cambiado a un blanco casi transparente */
      background: rgba(255, 255, 255, 0.1);
      border: 1px dashed #fff;
      z-index: 1;
    }
    /* --- FIN DE ESTILOS MODIFICADOS --- */
    
    .key-point {
      position: absolute;
      width: 3px;
      height: 3px;
      background: red;
      border-radius: 50%;
      z-index: 2;
    }
    
    p {
      position: absolute;
      padding: 5px;
      background: #007f8b;
      color: #fff;
      font-size: 12px;
      margin: 0;
      z-index: 2;
    }
  </style>
</head>
<body>
  <h1>Face Detection Demo</h1>
  <div id="liveView" class="videoView">
    <video id="webcam" autoplay playsinline></video>
  </div>
  <canvas id="snapshotCanvas" style="display: none;"></canvas>
</body>
</html>